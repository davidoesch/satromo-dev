{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <span style=\"color:#336699\">Image processing on images obtained through STAC</span>\n",
    "<hr style=\"border:2px solid #0077b9;\">\n",
    "<div style=\"text-align: left;\">\n",
    "    <a href=\"https://nbviewer.jupyter.org/github/davidoesch/satromo-dev/blob/main/codegallery/jupyter/Python/stac/stac-image-processing.ipynb\"><img src=\"https://raw.githubusercontent.com/jupyter/design/master/logos/Badges/nbviewer_badge.svg\" align=\"center\"/></a>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<b>Abstract.</b> This Jupyter Notebook describes how to search for data <em>SwissEO</em> products in data.geo.admin.ch's catalog through the STAC service. Then it shows how to use Python libraries to perform some image processing. It starts by computing the Normalized Difference Vegetation Index (NDVI) based on the red and near-infrared spectral bands. Next, it demonstrates a threshold analysis based on the computed NDVI. Lastly, it computes the NDVI difference for images from two diffrent dates.\n",
    "</div>\n",
    "\n",
    "<br/>\n",
    "<div style=\"text-align: justify;  margin-left: 25%; margin-right: 25%;font-size: 75%; border-style: solid; border-color: #0077b9; border-width: 1px; padding: 5px;\">\n",
    "    <b>For an introduction to the SpatioTemporal Asset Catalog (STAC) with the data.geo.admin.ch infrastructure, please, refer to the following Jupyter Notebook:</b>\n",
    "    <div style=\"margin-left: 10px; margin-right: 10px\">\n",
    "    <a href=\"./stac-introduction.ipynb\" target=\"_blank\">Introduction to the SpatioTemporal Asset Catalog (STAC)</a>.\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# STAC Client API\n",
    "<hr style=\"border:1px solid #0077b9;\">\n",
    "\n",
    "For running the examples in this Jupyter Notebook you will need to install the [STAC client for Python](https://github.com/brazil-data-cube/stac.py). To install it from PyPI using `pip`, use the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pystac-client in /media/menas/data/projects/satromo-dev/.venv/lib/python3.10/site-packages (0.8.5)\n",
      "Requirement already satisfied: requests>=2.28.2 in /media/menas/data/projects/satromo-dev/.venv/lib/python3.10/site-packages (from pystac-client) (2.32.3)\n",
      "Requirement already satisfied: pystac>=1.10.0 in /media/menas/data/projects/satromo-dev/.venv/lib/python3.10/site-packages (from pystac[validation]>=1.10.0->pystac-client) (1.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /media/menas/data/projects/satromo-dev/.venv/lib/python3.10/site-packages (from pystac-client) (2.8.2)\n",
      "Requirement already satisfied: jsonschema~=4.18 in /media/menas/data/projects/satromo-dev/.venv/lib/python3.10/site-packages (from pystac[validation]>=1.10.0->pystac-client) (4.23.0)\n",
      "Requirement already satisfied: six>=1.5 in /media/menas/data/projects/satromo-dev/.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pystac-client) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /media/menas/data/projects/satromo-dev/.venv/lib/python3.10/site-packages (from requests>=2.28.2->pystac-client) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /media/menas/data/projects/satromo-dev/.venv/lib/python3.10/site-packages (from requests>=2.28.2->pystac-client) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /media/menas/data/projects/satromo-dev/.venv/lib/python3.10/site-packages (from requests>=2.28.2->pystac-client) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /media/menas/data/projects/satromo-dev/.venv/lib/python3.10/site-packages (from requests>=2.28.2->pystac-client) (2024.8.30)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /media/menas/data/projects/satromo-dev/.venv/lib/python3.10/site-packages (from jsonschema~=4.18->pystac[validation]>=1.10.0->pystac-client) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /media/menas/data/projects/satromo-dev/.venv/lib/python3.10/site-packages (from jsonschema~=4.18->pystac[validation]>=1.10.0->pystac-client) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /media/menas/data/projects/satromo-dev/.venv/lib/python3.10/site-packages (from jsonschema~=4.18->pystac[validation]>=1.10.0->pystac-client) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /media/menas/data/projects/satromo-dev/.venv/lib/python3.10/site-packages (from jsonschema~=4.18->pystac[validation]>=1.10.0->pystac-client) (0.21.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pystac-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rasterio in /media/menas/data/projects/satromo-dev/.venv/lib/python3.10/site-packages (1.3.8)\n",
      "Requirement already satisfied: shapely in /media/menas/data/projects/satromo-dev/.venv/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: matplotlib in /media/menas/data/projects/satromo-dev/.venv/lib/python3.10/site-packages (3.9.2)\n",
      "Requirement already satisfied: affine in /media/menas/data/projects/satromo-dev/.venv/lib/python3.10/site-packages (from rasterio) (2.4.0)\n",
      "Requirement already satisfied: attrs in /media/menas/data/projects/satromo-dev/.venv/lib/python3.10/site-packages (from rasterio) (23.1.0)\n",
      "Requirement already satisfied: certifi in /media/menas/data/projects/satromo-dev/.venv/lib/python3.10/site-packages (from rasterio) (2024.8.30)\n",
      "Requirement already satisfied: click>=4.0 in /media/menas/data/projects/satromo-dev/.venv/lib/python3.10/site-packages (from rasterio) (8.1.7)\n",
      "Requirement already satisfied: cligj>=0.5 in /media/menas/data/projects/satromo-dev/.venv/lib/python3.10/site-packages (from rasterio) (0.7.2)\n",
      "Requirement already satisfied: numpy>=1.18 in /media/menas/data/projects/satromo-dev/.venv/lib/python3.10/site-packages (from rasterio) (1.25.2)\n",
      "Requirement already satisfied: snuggs>=1.4.1 in /media/menas/data/projects/satromo-dev/.venv/lib/python3.10/site-packages (from rasterio) (1.4.7)\n",
      "Requirement already satisfied: click-plugins in /media/menas/data/projects/satromo-dev/.venv/lib/python3.10/site-packages (from rasterio) (1.1.1)\n",
      "Requirement already satisfied: setuptools in /media/menas/data/projects/satromo-dev/.venv/lib/python3.10/site-packages (from rasterio) (68.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /media/menas/data/projects/satromo-dev/.venv/lib/python3.10/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /media/menas/data/projects/satromo-dev/.venv/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /media/menas/data/projects/satromo-dev/.venv/lib/python3.10/site-packages (from matplotlib) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /media/menas/data/projects/satromo-dev/.venv/lib/python3.10/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /media/menas/data/projects/satromo-dev/.venv/lib/python3.10/site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in /media/menas/data/projects/satromo-dev/.venv/lib/python3.10/site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /media/menas/data/projects/satromo-dev/.venv/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /media/menas/data/projects/satromo-dev/.venv/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /media/menas/data/projects/satromo-dev/.venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install rasterio shapely matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to access the funcionalities of the client API, you should import the `pystac_client` package, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystac_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, you can check the installed `pystac_client` package version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.8.5'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pystac_client.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Then, create a `STAC` object attached to the data.geo.admin.ch STAC service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = pystac_client.Client.open('https://data.geo.admin.ch/api/stac/v0.9/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the \"Swisstopo finish\" STAC implementation,  we need to add the conformance classes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.add_conforms_to(\"COLLECTIONS\")\n",
    "service.add_conforms_to(\"ITEM_SEARCH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching for Sentinel-2 Images\n",
    "<hr style=\"border:1px solid #0077b9;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the STAC `search` API to look for images from collection named `ch.swisstopo.swisseo_s2-sr_v100`. This collection is a temporal composite from Sentinel-2/MSI surface reflectance data. Let's define a search box with the following bounds: $x_{min} = 7.364515,$, $x_{max} = 7.535312$, $y_{min} = -46.868545,$, $y_{max} = -46.999127$. Besides that, the period of interest ranges from August 1st, 2018 to July 31st, 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = (7.364515, 46.868545, 7.535312, 46.999127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_search = service.search(collections=['ch.swisstopo.swisseo_s2-sr_v100'],\n",
    "                             bbox=bbox,\n",
    "                             datetime='2018-08-01/2019-07-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 124 items\n"
     ]
    }
   ],
   "source": [
    "items = list(item_search.items())\n",
    "print(f\"Found {len(items)} items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to filter for items, which are at least 20% cloudfree. Since <em>SwissEO</em> is in `EPSG 2056`, we need first to transform th `bbox` accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyproj import Transformer\n",
    "\n",
    "# Create a transformer object\n",
    "transformer = Transformer.from_crs(\"EPSG:4326\", \"EPSG:2056\", always_xy=True)\n",
    "\n",
    "# Transform the coordinates\n",
    "x_min, y_min = transformer.transform(bbox[0], bbox[1])\n",
    "x_max, y_max = transformer.transform(bbox[2], bbox[3])\n",
    "\n",
    "# Create the new bounding box in EPSG:2056\n",
    "bbox_2056 = (x_min, y_min, x_max, y_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No we create a function to test if an item is cloudfree enough. The function with `rasterio` will stream each `mask_10m.tif` file and check the second band if the values in the `bbox_2056` do at least have at least 20% 0 values - cloudfree pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy \n",
    "def is_cloud_free_enough(item, bbox_2056, threshold=0.2):\n",
    "    assets = item.assets\n",
    "    asset_key_mask = next((key for key in assets.keys() if key.endswith('masks-10m.tif')), None)\n",
    "    \n",
    "    if asset_key_mask is None:\n",
    "        return False\n",
    "    \n",
    "    with rasterio.open(assets[asset_key_mask].href) as src:\n",
    "        window = src.window(*bbox_2056)\n",
    "        cloud = src.read(2, window=window)\n",
    "        \n",
    "        # Calculate the percentage of cloud-free pixels (0 values)\n",
    "        cloud_free_percentage = numpy.sum(cloud == 0) / cloud.size\n",
    "        \n",
    "        return cloud_free_percentage >= threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's filter  our items with this function, since it will take a while to scan through the plethora of data we will use a prgress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "filtered_items = []\n",
    "for item in tqdm(items, desc=\"Checking items\", unit=\"item\"):\n",
    "    if is_cloud_free_enough(item, bbox_2056):\n",
    "        filtered_items.append(item)\n",
    "\n",
    "print(f\"Original number of items: {len(items)}\")\n",
    "print(f\"Number of items with at least 20% cloud-free area: {len(filtered_items)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now our mostly cloudfree items in `filtered_items`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral Indices\n",
    "<hr style=\"border:1px solid #0077b9;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spectral indices are computed using sensor bands to highlight a certain feature of a target or reduce certain effects. In this context, vegetation indices are spectral indices that enhance characteristics of vegetation, using bands such as Near Infra-red (`NIR`), a region where vegetation shows the most intense reflectance and bands located in red, where the vegetation has the highest absorption of visible sunlight due to the presence in its constitution of the green pigment chlorophyll (Meneses, 2012). The behavior of these spectral bands in some types of targets can be observed below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://brazil-data-cube.github.io/_images/spectral-profile.png\" width=\"480\" />\n",
    "<br/>\n",
    "Spectral profile of several targets. Source: modified from Pan et. al (2015).\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the Normalized Difference Vegetation Index (NDVI)\n",
    "<hr style=\"border:1px solid #0077b9;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The normalized difference vegetation index (NDVI) is calculated using the **Red** and **Near Infrared** (NIR) spectral bands. It assesses whether or not the target being observed contains live green vegetation. It can be calculated through the following equation:\n",
    "\n",
    "$$\n",
    "NDVI = \\frac{(NIR - RED)}{(NIR + RED)}\n",
    "$$\n",
    "\n",
    "<center><b>Equation 1</b> - NDVI.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to compute the NDVI just with images from the first item:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#items = list(item_search.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = filtered_items[0]\n",
    "item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify;  margin-left: 15%; margin-right: 15%; border-style: solid; border-color: #0077b9; border-width: 1px; padding: 5px;\">\n",
    "    <b>Note:</b> <em>SwissEO</em> already provides the <em>VHI</em> alongside with the spectral bands for the item, besides the quality indicators (<em>MASKS</em>, <em>CLOUD</em>, <em>CLOUDPROBABILITY</em>, <em>CLOUD&TERRAINSHADOW</em>).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The assets with the links to the images, thumbnails or specific metadata files, can be accessed through the property `assets` (from a given item):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets = item.assets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data of the Sentinel-2 10 bands is available under the dictionary key which do end with`bands-10m.tif`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_key_10m = next((key for key in assets.keys() if key.endswith('bands-10m.tif')), None)\n",
    "band10m_asset = assets[asset_key_10m]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metadata of the Sentinel-2 10 bands is available under the dictionary key which do end with`metadata.json`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_key_metadata = next((key for key in assets.keys() if key.endswith('metadata.json')), None)\n",
    "metadata_asset = assets[asset_key_metadata ]\n",
    "print(metadata_asset.href)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can see in the above linked json, the `B04`red wavelength  correspond to the the first band 1 in  'bands-10m.tif' and `B08` near-infrared to the band 4.\n",
    "\n",
    "Now we retrieve with `rasterio` method the part of an image according to a rectangle specified in `bbox_2056`. We get then `red` and `nir` bands, which we scale back to radiance by factor 10'000:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(assets[asset_key_10m].href) as src:\n",
    "    window = src.window(*bbox_2056)   \n",
    "    red = src.read(1, window=window)/10000  \n",
    "    nir = src.read(4, window=window)/10000  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify;  margin-left: 15%; margin-right: 15%; border-style: solid; border-color: #0077b9; border-width: 1px; padding: 5px;\">\n",
    "    <b>Note:</b> If there are errors because of your pyproj version, you can run the code below as specified in <a  href=\"https://rasterio.readthedocs.io/en/latest/faq.html#why-can-t-rasterio-find-proj-db-rasterio-from-pypi-versions-1-2-0\" target=\"_blank\">rasterio documentation</a> and try again:\n",
    "\n",
    "       import os\n",
    "       del os.environ['PROJ_LIB']\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the retrieved data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(red, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(nir, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's compute the NDVI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi = (nir - red)/(nir + red)\n",
    "ndvi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the Matplotlib to visualize the result array, we subpress values lowert than 0, since they represent water:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ndvi, cmap='gray',vmin=0, vmax=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot using other colormaps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ndvi, cmap='jet',vmin=0, vmax=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more colormaps check https://matplotlib.org/stable/tutorials/colors/colormaps.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram\n",
    "<hr style=\"border:1px solid #0077b9;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram of a digital image, also known as frequency distribution, is the graphic representation in columns showing the intensity of values and the number of pixels with such intensity and is the basis for several types of digital image processing (Gonzalez & Woods, 2007). Some types of histogram can be observed below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://brazil-data-cube.github.io/_images/histogram.png\" width=\"480\" />\n",
    "<br/>\n",
    "Four types of images: dark, bright, low contrast and high contrast, and their respective histograms. Source: (Gonzalez & Woods, 2007).\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thresholding images\n",
    "<hr style=\"border:1px solid #0077b9;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Digital image Classification is a broad topic and basically consists of assigning labels to targets in a dataset, also called classes. Although many of the classification approaches are complex, there are some simple approaches to solving certain problems, such as thresholding.\n",
    "\n",
    "The idea of assigning a class following a threshold assumes that the data can be separated by a simple \"line\", this can be seen in the next figures in a histogram:\n",
    "\n",
    "\n",
    "<center>\n",
    "<img src=\"https://scikit-image.org/docs/dev/_images/sphx_glr_plot_multiotsu_001.png\" width=\"960\" />\n",
    "<br/>\n",
    "Histogram limiarization example. Source: <a href=\"https://scikit-image.org/docs/dev/auto_examples/segmentation/plot_multiotsu.html\">scikit-image doc</a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to separate our data into groups according to their NDVI values.\n",
    "But first let's see how the image histogram behaves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"NDVI Histogram\")\n",
    "plt.hist(ndvi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supposing we can separate the `ndvi` image with threshold, we would assume for this specific case that:\n",
    "* all pixels with values below 0.2 are dark pixels;\n",
    "* all pixels above 0.45 are areas containing a good portion of vegetation.\n",
    "* all pixels with values from 0.2 to 0.45 are areas with few vegetation;\n",
    "\n",
    "We can perform this thresholding by selecting in the ndvi matrix all values belonging to a given range and assigning a common integer value. We assume the following integer values:\n",
    "* `1`: dark pixels;\n",
    "* `2`: vigorous vegetation;\n",
    "* `3`: weak vegetation.\n",
    "\n",
    "Let's first create a copy of the original ndvi matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_img = ndvi.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use the new copy of the ndvi array and assign the values according to each range of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_img[ndvi < 0.2] = 1 # < 0.2\n",
    "labeled_img[ndvi >= 0.2] = 3 # 0.2 - 0.45\n",
    "labeled_img[ndvi >= 0.45] = 2 # >= 0.45\n",
    "labeled_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's see the `ndvi` image separated into those labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [30, 20] #Change plot size\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(ndvi, cmap='gray')\n",
    "ax2.imshow(labeled_img, cmap='brg');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Image Difference\n",
    "<hr style=\"border:1px solid #0077b9;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's suppose we want to compare the VHI for images from two different dates and same location, for instance to verify the areas where crops have grown and areas that loss vegetation.\n",
    "\n",
    "For this computation we are going to use the VHI calculated from <em>SwissEO VHI</em>, and we will select two items (with the same location but with different dates) using STAC items.\n",
    "\n",
    "The first image comprises pixels from July 28th, 2019 to August 12th, 2019 (`2019-07-28_2019-08-12`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_search = service.search(collections=['ch.swisstopo.swisseo_s2-sr_v100'],\n",
    "                             bbox=bbox,\n",
    "                             datetime='2024-08-01/2023-07-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 items\n"
     ]
    }
   ],
   "source": [
    "items = list(item_search.items())\n",
    "print(f\"Found {len(items)} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "first_item = item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_first_image = read(first_item.assets['NDVI'].href, bbox=bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other selected image comprises pixels from `2018-07-28_2018-08-12` - i.e., one year before the first one selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_item = items[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_second_image = read(second_item.assets['NDVI'].href, bbox=bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify;  margin-left: 15%; margin-right: 15%; border-style: solid; border-color: #0077b9; border-width: 1px; padding: 5px;\">\n",
    "    <b>Note:</b> NDVI bands precomputed by BDC ranges from <em>-10000</em> to <em>10000</em>, instead of <em>-1</em> to <em>1</em>, as can be seen in the item metadata. This is due to the lower volume required to store files that use 16-bit integer values rather than 32-bit float.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering that these images are from an agricultural area and that crops are normally planted near August (first observation), in a six months, previous or after the first observation, it is expected to find crops, which will imply in greater NDVI values (more vigorous vegetation). This will cause NDVI band to present brighter values on these areas. Using the `gray` colormap, high value NDVI pixels will be more similar to white, while low value NDVI pixels will be closer to the black color.\n",
    "Based on that, let's visually compare both NDVI images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(ndvi_first_image, cmap='gray')\n",
    "ax2.imshow(ndvi_second_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming we want to see what have grown and what was loss, let's subtract the most recent image from the oldest one and plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_diff = ndvi_first_image - ndvi_second_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "plt.imshow(ndvi_diff, cmap='jet');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen in the the NDVI difference plot, the main changes on pixel values were found in agriculture areas, which was expected due to changes in crops.\n",
    "The blue values indicate negative values, while red values are positive. This means that for the blue areas there was a loss of vegetation, as a decreasing result on the NDVI value, meaning that crops were harvest. Meanwhile, on the red areas, the NDVI value increased as a result of the more vigorous vegetation on the recent date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "<hr style=\"border:1px solid #0077b9;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Python Client Library for STAC Service](https://pystac-client.readthedocs.io/en/latest/)\n",
    "\n",
    "- [Spatio Temporal Asset Catalog Specification](https://stacspec.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See also the following Jupyter Notebooks\n",
    "<hr style=\"border:1px solid #0077b9;\">\n",
    "\n",
    "* [Introduction to the SpatioTemporal Asset Catalog (STAC)](./stac-introduction.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
